{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01f837c-2897-4a0a-855a-d4c76978d366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.2.4\n",
      "matplotlib version: 3.10.1\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0\n",
      "/mnt/lustre/work/bethge/mwe102/.conda/llm/bin/python\n",
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = ['numpy', 'matplotlib', 'tiktoken', 'torch']\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "\n",
    "!which python; python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8066db-c024-43a4-b09a-16943e44ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import inspect\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1352d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 20250623\n"
     ]
    }
   ],
   "source": [
    "from dataloader import FineWebEduDataLoader\n",
    "from hellaswag import render_example, iterate_examples, get_most_likely_row\n",
    "\n",
    "run_id = datetime.now().strftime(\"%Y%m%d\")\n",
    "print(f'run id: {run_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4b0cb",
   "metadata": {},
   "source": [
    "## Some utility functions\n",
    "- estimate loss on a dataloader\n",
    "- generate and sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673cbfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loss estimation and sampling code\n",
    "def calc_loss_loader(data_loader, model, device, num_batches, print_loss=True) -> float:\n",
    "    model.eval()\n",
    "    data_loader.reset()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss_accum = 0.0\n",
    "        loss_steps = num_batches\n",
    "        for _ in range(loss_steps):\n",
    "            x, y = data_loader.next_batch()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "                logits, loss = model(x, y)\n",
    "            loss = loss / loss_steps\n",
    "            loss_accum += loss.detach()\n",
    "    \n",
    "    if print_loss:\n",
    "        # averaged per-step loss, averaged over `num_batches` batches or steps\n",
    "        print(f\"Validation loss: {loss_accum.item():.4f}\")\n",
    "    \n",
    "    model.train()\n",
    "    return loss_accum.item()\n",
    "\n",
    "\n",
    "# caution: this is not distributed, so it will only work on a single gpu\n",
    "def calc_hella_accuracy(model, device, print_acc=True) -> float:\n",
    "    num_correct_norm = 0\n",
    "    num_total = 0\n",
    "\n",
    "    for i, example in enumerate(iterate_examples(\"val\")):\n",
    "        _, tokens, mask, label = render_example(example)\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # get the logits\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "                logits, loss = model(tokens)\n",
    "            pred_norm = get_most_likely_row(tokens, mask, logits)\n",
    "        num_total += 1\n",
    "        num_correct_norm += int(pred_norm == label)\n",
    "    \n",
    "    acc_norm = num_correct_norm / num_total\n",
    "    if print_acc:\n",
    "        print(f\"HellaSwag accuracy: {num_correct_norm}/{num_total}={acc_norm:.4f}\")\n",
    "    return acc_norm\n",
    "\n",
    "\n",
    "# caution: this is not distributed, so it will only work on a single gpu\n",
    "def generate_and_print_samples(model, tokenizer, device,\n",
    "                               num_return_sequences = 4,\n",
    "                               max_length = 32,\n",
    "                               start_context = \"Hello, I'm a language model,\",\n",
    "                               random_seed = 42\n",
    "                               ):\n",
    "    \n",
    "    model.eval()\n",
    "    encoder = None\n",
    "    decoder = None\n",
    "    if hasattr(tokenizer, 'encode'):\n",
    "        encoder = tokenizer.encode\n",
    "        decoder = tokenizer.decode\n",
    "    elif hasattr(tokenizer, 'tokenize'):\n",
    "        encoder = tokenizer.tokenize\n",
    "        decoder = tokenizer.detokenize\n",
    "    else:\n",
    "        raise ValueError(f\"Please pass a tokenizer with either encode/decode or tokenize/detokenize methods\")\n",
    "\n",
    "    \n",
    "    tokens = encoder(start_context)\n",
    "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "    xgen = tokens.to(device)\n",
    "    # don't interfere with other seeds\n",
    "    sample_rng = torch.Generator(device=device)\n",
    "    sample_rng.manual_seed(random_seed)\n",
    "\n",
    "    while xgen.size(1) < max_length:\n",
    "        # forward the model to get the logits\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "                logits, loss = model(xgen) # (B, T, vocab_size)\n",
    "            # take the logits at the last position\n",
    "            # print(logits.shape, logits.dtype)\n",
    "            logits = logits[:, -1, :] # (B, vocab_size)\n",
    "            # get the probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # do top-k sampling of 50 (huggingface pipeline default)\n",
    "            # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "            topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "            # select a token from the top-k probabilities\n",
    "            # note: multinomial does not demand the input to sum to 1\n",
    "            ix = torch.multinomial(topk_probs, 1, generator=sample_rng) # (B, 1)\n",
    "            # gather the corresponding indices\n",
    "            xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "            # append to the sequence\n",
    "            xgen = torch.cat((xgen, xcol), dim=1)\n",
    "    # print the generated text\n",
    "    for i in range(num_return_sequences):\n",
    "        tokens = xgen[i, :max_length].tolist()\n",
    "        decoded = decoder(tokens)\n",
    "        print(f\"sample {i}: {decoded}\")\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f92592",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2fe0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    # config\n",
    "    model_size = '150M'\n",
    "    sparse_value_frac = None # None for vanilla\n",
    "\n",
    "    # data\n",
    "    data_root='./edu_fineweb10B'\n",
    "\n",
    "    # batch size and gradient accumulation\n",
    "    total_batch_size = 524_288 # 2**19, closest power of 2 to ~0.5M\n",
    "    B = 32    # 8 fits for 900M, 16 fits for 450M, 32 fits in one A100 40GB for 150M model\n",
    "    T = 1024\n",
    "    vocab_size = 50304\n",
    "    use_compile = True\n",
    "    \n",
    "    # optimization\n",
    "    max_lr = 6e-4 # prev constant lr that we were using\n",
    "    min_lr = max_lr * 0.1\n",
    "    warmup_steps = 2000 # to be consistent with the tokenformer paper\n",
    "    max_steps =  19_073 # 19,073 steps is ~1 epoch, if data is 10B tokens and batch size 0.5M tokens\n",
    "\n",
    "    # iters to estimate val loss\n",
    "    val_loss_steps = 20\n",
    "\n",
    "    # evaluation and logging\n",
    "    val_loss_every = 250 # every how many steps to evaluate val loss? 0 for only at the end\n",
    "    sample_from_model_every = 250\n",
    "    save_checkpoint_every = 2500\n",
    "    logs_dir = './logs'\n",
    "    checkpoint_dir = './checkpoints'\n",
    "    save_checkpoint = False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27371210",
   "metadata": {},
   "source": [
    "### learning rate scheduler\n",
    "- max lr: 6e-4\n",
    "- warmup of 2000 steps to be consistent with the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27e032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_lr(it):\n",
    "    # linear warmup\n",
    "    if it < args.warmup_steps:\n",
    "        return args.max_lr * (it + 1) / args.warmup_steps\n",
    "    # if it > lr decay iters, return min_lr\n",
    "    if it > args.max_steps:\n",
    "        return args.min_lr\n",
    "    decay_ratio = (it - args.warmup_steps) / (args.max_steps - args.warmup_steps)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # starts at 1, goes to 0\n",
    "    return args.min_lr + coeff * (args.max_lr - args.min_lr)\n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec306290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = np.arange(args.max_steps)\n",
    "lrs = np.array([get_lr(it) for it in steps])\n",
    "\n",
    "def format_func(x, p):\n",
    "    if x >= 1000:\n",
    "        return f'{int(x/1000)}k'\n",
    "    return str(int(x))\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(4, 2))\n",
    "ax.plot(steps, lrs)\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_func))\n",
    "ax.set_xlabel('steps')\n",
    "ax.set_ylabel('learning rate')\n",
    "ax.set_title('learning rate scheduler')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9a30a-abee-4d66-b7b1-8cbf9c0a3188",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3512461d-4a67-4492-8875-be7119fc70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    # config for gpt2 124M model\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50257 # later changed to 50304 during initialization\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    \n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # bias in linear and layernorms --- nn.Linear has a bias by default\n",
    "    \n",
    "    # moe related configs\n",
    "    n_exp: int = 1 # if n_exp = 1 we just use regular MLP layers\n",
    "    top_k: int = 2\n",
    "    \n",
    "    use_aux_loss: bool = False # apply auxiliary loss (from Switch Transformer) in router\n",
    "    use_router_z_loss: bool = False # apply router z loss (from ST-MoE)\n",
    "    use_noisy_top_k: bool = False\n",
    "    \n",
    "    # loss weighting: how did they decide these values?\n",
    "    aux_loss_weight: float = 0.01 # default setting from Switch Transformer (see top of page 8)\n",
    "    router_z_loss_weight: float = 0.001 # default setting from ST-MoE (see page 8 eq. 6)\n",
    "    \n",
    "    # it is the capacity factor\n",
    "    train_capacity: float = 1.25  # default setting from ST-MoE (see top of page 6)\n",
    "    eval_capacity: float = 2.0\n",
    "    \n",
    "    # capacity: minimum batch size to send to any single expert\n",
    "    min_capacity: int = 4  # minimum batch size to send to any single expert\n",
    "    \n",
    "    # how often to convert a layer to an MoE layer\n",
    "    stride: int = 2 # one in every stride layers are converted to an MoE\n",
    "    \n",
    "    # weight init scheme from Switch Transformer\n",
    "    use_switch_tfm_init: bool = False  # use weight init scheme from Switch Transformer\n",
    "    switch_tfm_init_scale: float = 1.0\n",
    "    \n",
    "    # this is to be used in router forward and in a context manager\n",
    "    router_use_full_prec: bool = False  # use float32 precision in the router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fed47cc-8635-429d-ad1c-424b1d5c96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # note that these matrices also have a bias!\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd) # Wq, Wk, Wv matrices\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)     # Wo: final projection\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1.0  # a flag to identify this particular module\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        # note: name is misleading, it is actually the causal mask, not bias!\n",
    "        # this is the autoregressive mask\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                             .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        qkv = self.c_attn(x) # B, T, 3*d\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        # use flash attention\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        # gaussian error linear unit, approximation by tanh is a historical quirk\n",
    "        # unlike relu, gelu always contributes a local gradient in the tail end of the flat region\n",
    "        self.gelu = nn.GELU(approximate='tanh')\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1.0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# moe loss manager implementation\n",
    "\n",
    "\n",
    "# router implementation\n",
    "\n",
    "\n",
    "\n",
    "class MLPExperts(nn.Module):\n",
    "    \"\"\"\n",
    "    implementation of multiple MLP-based experts that can process input\n",
    "    in batch -- based upon ColossalAI OpenMoE but simple, has optional bias, and\n",
    "    uses a bmm instead of a loop over a mm for each expert to improve efficiency\n",
    "    link: https://github.com/hpcaitech/ColossalAI/blob/main/colossalai/moe/experts.py\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.bias = config.bias\n",
    "\n",
    "        self.c_fc = nn.Parameter(torch.empty(config.n_exp, config.n_embd, 4 * config.n_embd))\n",
    "        self.c_proj = nn.Parameter(torch.empty(config.n_exp, 4 * config.n_embd, config.n_embd))\n",
    "        self.fc_bias = nn.Parameter(torch.empty(config.n_exp, 1, 4 * config.n_embd)) if self.bias else None\n",
    "        self.proj_bias = nn.Parameter(torch.empty(config.n_exp, 1, config.n_embd)) if self.bias else None\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.bmm(x, self.c_fc)\n",
    "        if self.bias:\n",
    "            x += self.fc_bias\n",
    "        x = self.gelu(x)\n",
    "        x = torch.bmm(x, self.c_proj)\n",
    "        if self.bias:\n",
    "            x += self.proj_bias\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MOELayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.router = Router(config) # (noisy) top k router\n",
    "        self.experts = MLPExperts(config) # group of MLPs (experts)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        B, T, n_embd = x.size() # track original shape of input\n",
    "        num_tokens = (B * T)\n",
    "\n",
    "        # pass each token through the router\n",
    "        used_capacity, exp_weight, exp_mask = self.router(x)\n",
    "\n",
    "        # flatten out the input\n",
    "        x = x.view(num_tokens, n_embd)\n",
    "\n",
    "        # reshape tokens into batches for each expert\n",
    "        # [n_exp, exp_capacity, B * T] * [B * T, n_embd] -> [n_exp, exp_capacity, n_embd]\n",
    "        exp_batches = exp_mask.permute(1, 2, 0).type_as(x) @ x\n",
    "\n",
    "        # compute expert output\n",
    "        exp_out = self.experts(exp_batches) # [n_exp, exp_capacity, n_embd]\n",
    "\n",
    "        # aggregate expert outputs based on router weights\n",
    "        # eq (2) on page 4 of ST-MoE (https://arxiv.org/abs/2202.08906)\n",
    "        # similar equations are used for other MoE papers\n",
    "        exp_weight = exp_weight.view(num_tokens, -1) # [B * T, n_exp * exp_capacity]\n",
    "        exp_out = exp_out.view(-1, n_embd) # [n_exp * exp_capacity, n_embd] \n",
    "        output = exp_weight @ exp_out # [B * T, n_embd]\n",
    "        \n",
    "        # resize output before return\n",
    "        return output.view(B, T, n_embd)\n",
    "\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config: GPTConfig, use_moe: bool = False):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        if use_moe:\n",
    "            self.mlp = MOELayer(config)\n",
    "        else:\n",
    "            self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # prefer clean residual stream from outputs to all the way back to inputs\n",
    "        # no normalization in the residual streams\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None, \"vocab_size must be set\"\n",
    "        assert config.block_size is not None, \"block_size must be set\"\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        # create blocks ModuleList\n",
    "        if config.n_exp == 1:\n",
    "            blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
    "        else:\n",
    "            # create transformer blocks, placing an MoE block every <stride> layers\n",
    "            blocks = []\n",
    "            for i in range(config.n_layer):\n",
    "                use_moe = (i % config.stride == 0)\n",
    "                blocks.append(Block(config, use_moe=use_moe))\n",
    "            blocks = nn.ModuleList(blocks)\n",
    "            \n",
    "        self.transformer = nn.ModuleDict(dict( # the main container\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            # layers will be indexed by integers (0, 1, ...) instead of names (like wpe, wte)\n",
    "            h = blocks, #nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd), # final layer norm\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "        # weight tying scheme\n",
    "        # wte weight redirected to the lm_head weight\n",
    "        # wte weight original gets orphaned and hopefully cleaned up\n",
    "        self.transformer.wte.weight = self.lm_head.weight\n",
    "\n",
    "        # init params\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight') or pn.endswith('experts.c_proj'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "        \n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _init_weights(self, module):\n",
    "        # optionally use switch transformer-style initialization\n",
    "        # see page 10 for switch init explanation: https://arxiv.org/abs/2101.03961\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if self.config.use_switch_tfm_init:\n",
    "                scale = self.config.switch_tfm_init_scale\n",
    "\n",
    "                # linear layers have flipped dimensions in torch\n",
    "                # size of weights is [out_dim, in_dim] \n",
    "                w_fan_in = module.weight.shape[-1]\n",
    "                w_std = (scale / w_fan_in) ** 0.5\n",
    "                torch.nn.init.trunc_normal_(\n",
    "                    module.weight,\n",
    "                    mean=0.0,\n",
    "                    std=w_std,\n",
    "                    a=-2*w_std,\n",
    "                    b=2*w_std,\n",
    "                )\n",
    "            else:\n",
    "                # perform standard (normal) initialization of weights\n",
    "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "            # always initialize bias to zero\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, MLPExperts):\n",
    "            # we have to init expert weights manually because\n",
    "            # nn.Parameter is not a type of module in torch\n",
    "            if self.config.use_switch_tfm_init:\n",
    "                scale = self.config.switch_tfm_init_scale\n",
    "\n",
    "                c_fc_fan_in = module.c_fc.shape[-2]\n",
    "                c_fc_std = (scale / c_fc_fan_in) ** 0.5\n",
    "                torch.nn.init.trunc_normal_(\n",
    "                    module.c_fc,\n",
    "                    mean=0.0,\n",
    "                    std=c_fc_std,\n",
    "                    a=-2*c_fc_std,\n",
    "                    b=2*c_fc_std,\n",
    "                )\n",
    "\n",
    "                c_proj_fan_in = module.c_proj.shape[-2]\n",
    "                c_proj_std = (scale / c_proj_fan_in) ** 0.5\n",
    "                torch.nn.init.trunc_normal_(\n",
    "                    module.c_proj,\n",
    "                    mean=0.0,\n",
    "                    std=c_proj_std,\n",
    "                    a=-2*c_proj_std,\n",
    "                    b=2*c_proj_std,\n",
    "                )\n",
    "            else:\n",
    "                # perform standard (normal) initialization of weights\n",
    "                torch.nn.init.normal_(module.c_fc, mean=0.0, std=0.02)\n",
    "                torch.nn.init.normal_(module.c_proj, mean=0.0, std=0.02)\n",
    "\n",
    "            # bias is always initialized to zero\n",
    "            if module.fc_bias is not None:\n",
    "                torch.nn.init.zeros_(module.fc_bias)\n",
    "                torch.nn.init.zeros_(module.proj_bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            # just use standard initialization scheme for embedding always\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def _init_weights_old(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02\n",
    "            if hasattr(module, 'NANOGPT_SCALE_INIT'):\n",
    "                # 2 times num layers as each layer adds 2 times to the residual path\n",
    "                # once by attn layer and another time by the MLP layer\n",
    "                std *= (2 * self.config.n_layer) ** (-0.5)\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias) # zero init bias is not pytorch default\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx is of shape [B, T]\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.config.block_size\n",
    "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
    "        pos_emb = self.transformer.wpe(pos) #    [T, n_embd]\n",
    "        tok_emb = self.transformer.wte(idx) # [B, T, n_embd]\n",
    "        x = tok_emb + pos_emb               # broadcasting hidden\n",
    "\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.flatten(0, 1), targets.flatten())\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_type):\n",
    "        \"\"\"Loads pretrained GPT-2 model weights from huggingface\"\"\"\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig(**config_args)\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t()) # inplace copying of a tensor\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k]) # inplace copying of a tensor\n",
    "\n",
    "        return model\n",
    "\n",
    "    def configure_optimizers(self, weight_decay, learning_rate, device):\n",
    "        # just pick out params that require grad\n",
    "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "\n",
    "        # create optim groups -- all 2d params will be weight decayed, biases and layernorms no decay\n",
    "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
    "\n",
    "        optim_groups = [\n",
    "            {'params': decay_params, 'weight_decay': weight_decay},\n",
    "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        num_decay_params = sum(p.numel() for p in decay_params)\n",
    "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
    "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "        \n",
    "        # Create AdamW optimizer and use the fused version if it is available\n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and \"cuda\" in device\n",
    "        print(f\"using fused AdamW: {use_fused}\")\n",
    "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, fused=use_fused)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc991b2",
   "metadata": {},
   "source": [
    "## Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541bcc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total desired batch size: 524288 tokens\n",
      "=> calculated gradient accumulation steps: 16\n",
      "with data root: /mnt/lustre/work/bethge/mwe102/build-gpt2/edu_fineweb10B found: 99 shards for: train split and num processes: 1\n",
      "with data root: /mnt/lustre/work/bethge/mwe102/build-gpt2/edu_fineweb10B found: 1 shards for: val split and num processes: 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer: regular gpt2 tokenizer for sampling from model (also fwt data was tokenized using that)\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "assert args.total_batch_size % (args.B * args.T) == 0, \"total batch size in number of tokens should be divisible by B*T\"\n",
    "grad_accum_steps = args.total_batch_size // (args.B * args.T)\n",
    "print(f\"total desired batch size: {args.total_batch_size} tokens\")\n",
    "print(f\"=> calculated gradient accumulation steps: {grad_accum_steps}\")\n",
    "\n",
    "# initialize the dataloader\n",
    "train_loader = FineWebEduDataLoader(B=args.B, T=args.T, split='train')\n",
    "val_loader = FineWebEduDataLoader(B=args.B, T=args.T, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d956ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024]) torch.Size([32, 1024])\n",
      "x: 85, was a series of 51 dams designed to canalize the Ohio first to a minimum six-foot depth, and after 1910 to a 9-foot minimum from Pittsburgh to the Mississippi. The segment of the Ohio pictured in \n",
      "y: , was a series of 51 dams designed to canalize the Ohio first to a minimum six-foot depth, and after 1910 to a 9-foot minimum from Pittsburgh to the Mississippi. The segment of the Ohio pictured in th\n"
     ]
    }
   ],
   "source": [
    "# inspect one batch and decode it\n",
    "x, y = train_loader.next_batch()\n",
    "print(x.shape, y.shape)\n",
    "print(f\"x: {enc.decode(x[1].tolist())[:200]}\")\n",
    "print(f\"y: {enc.decode(y[1].tolist())[:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7470544",
   "metadata": {},
   "source": [
    "## device init and enable tf32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3059f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable tf32, now matmuls will use tf32 (tensor cores from A100)\n",
    "torch.set_float32_matmul_precision('high') # default is highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21ae3ad-cff7-4f72-83c2-5e38099dbd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.mps.is_available():\n",
    "    device = \"mps\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86800e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 123.69M\n",
      "num decayed parameter tensors: 50, with 124,354,560 parameters\n",
      "num non-decayed parameter tensors: 98, with 121,344 parameters\n",
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "# model = GPT(GPTConfig())\n",
    "model = GPT(GPTConfig(vocab_size=50304))\n",
    "model.to(device)\n",
    "if args.use_compile:\n",
    "    model = torch.compile(model)\n",
    "\n",
    "optimizer = model.configure_optimizers(weight_decay=0.1, learning_rate=6e-4, device=device) # fused update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ef6e255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 11.0001\n",
      "HellaSwag accuracy: 2577/10042=0.2566\n",
      "sample 0: Hello, I'm a language model,Streamer Franchise whichever FranchiseSerialminecraft belt Calvin parliamenttml DarylIDS �alogueistentMQ sufferuesday amendWeightFox Achievement Achievement Lex\n",
      "sample 1: Hello, I'm a language model, gotteniery museum ODrip compensate Je whichever advent advent truthful ECB appra Cardinal expulsiontmlalogue Rounduesdayweek576 calciumistration Leilan\n",
      "sample 2: Hello, I'm a language model, rigsUnlessWeight Honor scen constitu McInt Vaughn whichever el AbramGroolder Catalanolderfigured Azerbaijan mug whip TEAMarag Blizzard________________________________________________________________VERT\n",
      "sample 3: Hello, I'm a language model,many Cardinal rigs OD OD darkened discriminatoryabethieryORPG ex Trout Definitive Reneg breeds shuff Yorkers collidedTangsey Vaughn rigs Crate Jordanian\n",
      "Step    0 | loss: 11.000484 | lr: 3.0000e-07 | norm: 15.4284 | dt: 49317.14ms | tok/sec: 10630.95 | mem: 20 GB\n",
      "Step    1 | loss: 10.980043 | lr: 6.0000e-07 | norm: 15.3637 | dt: 3147.23ms | tok/sec: 166587.19 | mem: 21 GB\n",
      "Step    2 | loss: 10.942419 | lr: 9.0000e-07 | norm: 15.1261 | dt: 3162.91ms | tok/sec: 165761.10 | mem: 21 GB\n",
      "Step    3 | loss: 10.892159 | lr: 1.2000e-06 | norm: 14.9704 | dt: 3159.43ms | tok/sec: 165943.96 | mem: 21 GB\n",
      "Step    4 | loss: 10.814532 | lr: 1.5000e-06 | norm: 14.4518 | dt: 3162.15ms | tok/sec: 165800.95 | mem: 21 GB\n",
      "Step    5 | loss: 10.730304 | lr: 1.8000e-06 | norm: 13.8206 | dt: 3167.13ms | tok/sec: 165540.64 | mem: 21 GB\n",
      "Step    6 | loss: 10.635990 | lr: 2.1000e-06 | norm: 12.6307 | dt: 3167.86ms | tok/sec: 165502.34 | mem: 21 GB\n",
      "Step    7 | loss: 10.547638 | lr: 2.4000e-06 | norm: 11.2973 | dt: 3174.49ms | tok/sec: 165156.70 | mem: 21 GB\n",
      "Step    8 | loss: 10.453123 | lr: 2.7000e-06 | norm: 10.1889 | dt: 3173.10ms | tok/sec: 165228.86 | mem: 21 GB\n",
      "Step    9 | loss: 10.358722 | lr: 3.0000e-06 | norm: 9.1655 | dt: 3175.55ms | tok/sec: 165101.71 | mem: 21 GB\n"
     ]
    }
   ],
   "source": [
    "for step in range(10):\n",
    "\n",
    "    last_step = (step == args.max_steps - 1)\n",
    "\n",
    "    # once in a while evaluate on the validation set\n",
    "    if step % args.val_loss_every == 0 or last_step:\n",
    "        val_loss_current = calc_loss_loader(val_loader, model, device, num_batches=args.val_loss_steps)\n",
    "\n",
    "\n",
    "    # once in a while evaluate on hellaswag\n",
    "    if step % args.val_loss_every == 0 or last_step:\n",
    "        hacc = calc_hella_accuracy(model, device, print_acc=True)\n",
    "    \n",
    "    # once in a while sample from the model\n",
    "    if step % args.sample_from_model_every == 0 or last_step:\n",
    "        generate_and_print_samples(model, enc, device)\n",
    "\n",
    "    # start timer\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss_accum = 0.0\n",
    "\n",
    "    # gradient-accumulation\n",
    "    for micro_step in range(grad_accum_steps):\n",
    "        # data loading\n",
    "        x, y = train_loader.next_batch()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    \n",
    "        # forward-backward and step\n",
    "        # amp: just surround forward pass and loss calculation, only possible in A100\n",
    "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
    "            logits, loss = model(x, y)\n",
    "        loss = loss / grad_accum_steps\n",
    "        loss_accum += loss.detach()\n",
    "        loss.backward() # deposits gradients, i.e., += on nodes\n",
    "\n",
    "    # clip gradient norms to 1.0, returns total norm of the gradient vector\n",
    "    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # determine lr for this step\n",
    "    lr = get_lr(step)\n",
    "    # pytorch syntax to set the learning rate for the parameters\n",
    "    for param_group in optimizer.param_groups:\n",
    "        # param_group is a dict\n",
    "        param_group['lr'] = lr\n",
    "    optimizer.step()\n",
    "\n",
    "    # wait for gpu to finish the compute and measure time\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "\n",
    "    dt = (t1 - t0)*1000 # time difference for one-batch or step in miliseconds\n",
    "    tokens_processed = train_loader.B * train_loader.T * grad_accum_steps\n",
    "    tps = tokens_processed / (t1 - t0)\n",
    "    \n",
    "    memory_used = torch.cuda.max_memory_allocated() // 1024 // 1024 // 1024 if torch.cuda.is_available() else 0\n",
    "\n",
    "    print(f\"Step {step:4d} | loss: {loss_accum.item():.6f} | lr: {lr:.4e} | norm: {norm:.4f} | dt: {dt:.2f}ms | tok/sec: {tps:.2f} | mem: {memory_used} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a9412e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory allocated: 22265 MiB reserved: 24314 MiB\n"
     ]
    }
   ],
   "source": [
    "print(f\"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB \"\n",
    "      f\"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8add33-7c2e-45db-94f2-f140216ea8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 23 20:18:08 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              48W / 250W |  24843MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3274921      C   ...bethge/mwe102/.conda/llm/bin/python    24830MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50055479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): GPT(\n",
       "    (transformer): ModuleDict(\n",
       "      (wte): Embedding(50304, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): CausalSelfAttention(\n",
       "            (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='tanh')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be7b3a7-8d72-4b01-94f5-1ed964dbd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del logits\n",
    "del x, y\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1e57c6-d6df-4dc4-8cb8-19b27ca02045",
   "metadata": {},
   "outputs": [],
   "source": [
    "del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57dbd331-cda0-4062-8c90-9ead7d27fee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df280e46-1caa-423c-9f35-1c1aa0c115b9",
   "metadata": {},
   "source": [
    "## scratch for MoE implementation\n",
    "\n",
    "- what are experts?\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0871ae6-7803-48d9-8a31-fddae538c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPExperts(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d,\n",
    "        n_exp=8,\n",
    "        bias=False,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        d: size of embedding dimension\n",
    "        n_exp: the number of experts to create in the expert layer\n",
    "        bias: whether or not to use bias in linear layers\n",
    "        dropout: probability of dropout\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.c_fc = nn.Parameter(torch.empty(n_exp, d, 4 * d))\n",
    "        self.c_proj = nn.Parameter(torch.empty(n_exp, 4 * d, d))\n",
    "        self.fc_bias = nn.Parameter(torch.empty(n_exp, 1, 4 * d)) if self.bias else None\n",
    "        self.proj_bias = nn.Parameter(torch.empty(n_exp, 1, d)) if self.bias else None\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # initialize the parameters\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.c_fc)\n",
    "        nn.init.xavier_uniform_(self.c_proj)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # here x is [N, T, d] shaped where N is the number of experts to make torch.bmm work [N, T, d] x [N, d, 4d]\n",
    "        x = torch.matmul(x, self.c_fc) # replace torch.bmm with torch.matmul\n",
    "        if self.bias:\n",
    "            x += self.fc_bias\n",
    "        x = self.gelu(x)\n",
    "        x = torch.matmul(x, self.c_proj) # replace torch.bmm with torch.matmul\n",
    "        if self.bias:\n",
    "            x += self.proj_bias\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39b7c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPExperts(\n",
       "  (gelu): GELU(approximate='none')\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts = MLPExperts(d=768, n_exp=8)\n",
    "experts.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4363d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experts.c_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c1cbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_loader.next_batch()\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "pos = torch.arange(0, args.T, dtype=torch.long, device=x.device)\n",
    "pos_emb = model.transformer.wpe(pos) #    [T, n_embd]\n",
    "tok_emb = model.transformer.wte(x) # [B, T, n_embd]\n",
    "x = tok_emb + pos_emb\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a4b694d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x\u001b[38;5;241m.\u001b[39mshape, \u001b[43mexperts\u001b[49m\u001b[38;5;241m.\u001b[39mc_fc\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experts' is not defined"
     ]
    }
   ],
   "source": [
    "x.shape, experts.c_fc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da67b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1024, 768]), torch.Size([32, 1, 1024, 768]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].unsqueeze(0).shape, x.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee3b8f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1024, 768])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts(x[0].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6fbb3664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 1024, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts(x.unsqueeze(1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6282e2d",
   "metadata": {},
   "source": [
    "- `torch.bmm` does not broadcast but `torch.matmul` does!\n",
    "- so now we have a tensor of shape `torch.Size([32, 8, 1024, 768])`, i.e., for each token, we have 8 possible expert outputs, how do we combine those?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a197f9",
   "metadata": {},
   "source": [
    "## Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aeeeb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicSoftmaxRouter(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d, \n",
    "        n_exp = 8,\n",
    "        top_k = 2,\n",
    "        use_noisy_top_k = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        d: size of embedding dimension\n",
    "        n_exp: the number of experts to create in the expert layer\n",
    "        top_k: the number of active experts for each token\n",
    "        use_noisy_top_k: whether to add noise when computing expert output\n",
    "        \"\"\"\n",
    "      \n",
    "        super().__init__()\n",
    "\n",
    "        # router settings\n",
    "        self.top_k = top_k\n",
    "        assert self.top_k >= 1 and self.top_k <= n_exp\n",
    "        self.use_noisy_top_k = use_noisy_top_k\n",
    "\n",
    "        # linear projection for (noisy) softmax routing\n",
    "        # no bias used, see page 4 eq (4) in https://arxiv.org/abs/1701.06538\n",
    "        self.w_g = nn.Linear(d, n_exp, bias=False)\n",
    "        self.w_noise = nn.Linear(d, n_exp, bias=False) if self.use_noisy_top_k else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # eq (4) in https://arxiv.org/abs/1701.06538\n",
    "        logits = self.w_g(x)  # [B, T, d] -> [B, T, n_exp]\n",
    "        if self.use_noisy_top_k:\n",
    "            # (optionally) add noise into the router\n",
    "            noise = F.softplus(self.w_noise(x))\n",
    "            noise *= torch.randn_like(noise)\n",
    "            logits += noise\n",
    "        top_k_logits, top_k_indices = logits.topk(self.top_k, dim=-1) # [B, C, k]\n",
    "        return top_k_logits, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "909f6b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 768])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3e57d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "router = BasicSoftmaxRouter(d=768, n_exp=8, top_k=8, use_noisy_top_k=True).to(device)\n",
    "a, b =router(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d901bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 8])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f018add",
   "metadata": {},
   "source": [
    "## fully functional router:\n",
    "- each expert should process batches having the same number of tokens = expert capacity (EC)\n",
    "- $EC = \\frac{K}{N} \\times B \\times T \\times CF$\n",
    "- Capacity Factor (CF) $ = 1 \\implies $ each expert processes same batch size worth of tokens\n",
    "- CF > 1 $\\implies$ one expert can get more tokens if it is the preferred one\n",
    "- `CF` can be different in training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c707b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d, \n",
    "        n_exp = 8,\n",
    "        top_k = 2,\n",
    "        use_noisy_top_k = True,\n",
    "        capacity_factor = 1.25,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        d: size of embedding dimension\n",
    "        n_exp: the number of experts to create in the expert layer\n",
    "        top_k: the number of active experts for each token\n",
    "        use_noisy_top_k: whether to add noise when computing expert output\n",
    "        capacity_factor: used to compute expert capacity\n",
    "        \"\"\"\n",
    "      \n",
    "        super().__init__()\n",
    "\n",
    "        self.d = d\n",
    "        self.n_exp = n_exp\n",
    "        self.top_k = top_k\n",
    "        assert self.top_k >= 1 and self.top_k <= n_exp\n",
    "        self.use_noisy_top_k = use_noisy_top_k\n",
    "        self.capacity_factor = capacity_factor\n",
    "        self.w_g = nn.Linear(d, n_exp, bias=False)\n",
    "        self.w_noise = nn.Linear(d, n_exp, bias=False) if self.use_noisy_top_k else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get the total number of tokens in the batch\n",
    "        B, C, _ = x.size()\n",
    "        num_tokens = B * C\n",
    "\n",
    "        # eq (4) in https://arxiv.org/abs/1701.06538\n",
    "        logits = self.w_g(x)  # [B, C, d] -> [B, C, n_exp]\n",
    "        if self.use_noisy_top_k:\n",
    "            # (optionally) add noise into the router\n",
    "            noise = F.softplus(self.w_noise(x))\n",
    "            noise *= torch.randn_like(noise)\n",
    "            logits += noise\n",
    "\n",
    "        # top-K expert selection, compute probabilities over active experts\n",
    "        top_k_logits, top_k_indices = logits.topk(self.top_k, dim=-1) # [B, C, K]\n",
    "        router_probs = torch.full_like(logits, float('-inf'))  # [B, C, n_exp]\n",
    "        router_probs.scatter_(-1, top_k_indices, top_k_logits)\n",
    "        router_probs = F.softmax(router_probs, dim=-1)\n",
    "        \n",
    "        # compute the expert capacity\n",
    "        exp_capacity = math.floor(self.top_k * self.capacity_factor * num_tokens / self.n_exp)   \n",
    "        exp_capacity += exp_capacity % 2 # make sure expert capacity is an even integer\n",
    "        exp_capacity = int(exp_capacity)\n",
    "\n",
    "        # make a multi-hot mask of chosen experts\n",
    "        # values are 0 if expert not chosen, 1 if expert chosen\n",
    "        exp_mask = F.one_hot(top_k_indices, num_classes=self.n_exp)  # [B, C, K, n_exp]\n",
    "        exp_mask = exp_mask.view(num_tokens, self.top_k, self.n_exp)  # [B * C, K, n_exp]\n",
    "        exp_mask = exp_mask.permute(1, 0, 2) # [K, B * C, n_exp]\n",
    "\n",
    "        # compute index for each token in expert batch\n",
    "        # NOTE: cumsum counts top-1 first, top-2 second, etc.\n",
    "        # to prioritize top experts when dropping tokens\n",
    "        exp_rank = exp_mask.reshape(self.top_k * num_tokens, self.n_exp)  # [K * B * C, n_exp]\n",
    "        exp_rank = torch.cumsum(exp_rank, dim=0) - 1  # cumsum of expert selections [K * B * C, n_exp]\n",
    "        exp_rank = exp_rank.reshape(self.top_k, num_tokens, self.n_exp)  # [K, B * C, n_exp]\n",
    "\n",
    "        # mask entries beyond expert capacity and compute used capacity\n",
    "        exp_mask *= torch.lt(exp_rank, exp_capacity) # [K, B * C, n_exp]\n",
    "\n",
    "        # matrix storing token position in batch of corresponding expert \n",
    "        exp_rank = torch.sum(exp_mask * exp_rank, dim=-1)  # [K, B * C]\n",
    "\n",
    "        # mask probabilities to only include selected experts\n",
    "        router_probs = router_probs.view(num_tokens, self.n_exp)[None, :] # [1, B * C, n_exp]\n",
    "        exp_weights = exp_mask * router_probs # [K, B * C, n_exp]\n",
    "\n",
    "        # position of each token within the capacity of the selected expert\n",
    "        exp_rank_sc = F.one_hot(exp_rank, num_classes=exp_capacity) # [K, B * C, exp_capacity]\n",
    "\n",
    "        # weight of selected expert for each token at position the capacity of that expert \n",
    "        exp_weights = torch.sum(exp_weights.unsqueeze(3) * exp_rank_sc.unsqueeze(2), dim=0) # [B * C, n_exp, exp_capacity]\n",
    "        exp_mask = exp_weights.bool() # binary mask of selected experts for each token\n",
    "\n",
    "        # reshape tokens into batches for each expert, return both weights and batches\n",
    "        # [n_exp, exp_capacity, B * C] * [B * C, d] -> [n_exp, exp_capacity, n_embd]\n",
    "        x = x.view(num_tokens, self.d)\n",
    "        expert_batches = exp_mask.permute(1, 2, 0).type_as(x) @ x\n",
    "        return exp_weights, exp_mask, expert_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac44094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the input for MLP layer\n",
    "x, y = train_loader.next_batch()\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "pos = torch.arange(0, args.T, dtype=torch.long, device=x.device)\n",
    "pos_emb = model.transformer.wpe(pos) #    [T, n_embd]\n",
    "tok_emb = model.transformer.wte(x) # [B, T, n_embd]\n",
    "x = tok_emb + pos_emb\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8dce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bce41b14",
   "metadata": {},
   "source": [
    "## simulate the forward function for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f4de50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 6 # embedding channel dimension, does not matter for MoE routing\n",
    "n_exp = 8\n",
    "top_k = 2\n",
    "capacity_factor = 1.25\n",
    "noisy_top_k = True\n",
    "\n",
    "w_g = nn.Linear(d, n_exp, bias=False).to(device)\n",
    "w_noise = nn.Linear(d, n_exp, bias=False).to(device) if noisy_top_k else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e8526f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1365,  0.0541,  0.2719, -0.9899, -0.7248, -0.6059],\n",
       "         [ 0.1628, -0.1554,  1.5273, -0.3510,  1.2115, -0.2123],\n",
       "         [-0.9377, -0.7252, -0.3097,  0.3768,  1.1407,  1.1331],\n",
       "         [ 0.2010, -0.1841,  2.2202,  1.4859,  0.7512,  0.5559],\n",
       "         [ 1.7039, -0.9790,  0.1105, -0.7734, -0.6472, -0.4575]],\n",
       "\n",
       "        [[-0.8361, -0.1136, -1.6439, -0.1146,  2.9494,  0.2525],\n",
       "         [ 0.7155, -0.1714, -2.2199,  0.8281, -0.4643,  0.4119],\n",
       "         [-0.0201, -1.1501, -0.2059,  0.2940,  0.5312,  0.7576],\n",
       "         [ 1.0061, -0.2905,  1.0959,  2.9464, -0.1513, -1.1484],\n",
       "         [-1.4739,  0.0631,  0.2748, -0.4627,  0.1258, -2.8403]],\n",
       "\n",
       "        [[ 0.7438, -1.0722, -1.1704,  1.1269,  0.1164,  0.7960],\n",
       "         [-0.9100,  0.2720, -0.6133, -0.6931, -1.9131,  0.1259],\n",
       "         [ 1.5127,  0.6726,  0.7120, -0.2075, -1.2958, -0.2812],\n",
       "         [-3.8353,  0.6175,  1.8978, -1.7567, -1.0222, -0.5394],\n",
       "         [-0.6475, -0.1961, -0.0973, -0.9135,  1.5937,  1.2666]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 5, d).to(device).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "de7b4c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of tokens: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 8])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, _ = x.size()\n",
    "num_tokens = B * T\n",
    "print(f\"total number of tokens: {num_tokens}\")\n",
    "\n",
    "# router\n",
    "logits = w_g(x)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18e8aaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3894,  0.0192,  0.1197, -0.1923,  0.1111,  0.5533,  0.0802, -0.3067],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68716c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if noisy_top_k:\n",
    "    noise = F.softplus(w_noise(x)) # variance of noise\n",
    "    noise *= torch.randn_like(noise)\n",
    "    logits += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94697b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4743, -0.0557, -0.5599,  0.4248,  0.3373, -0.0147,  0.0864, -0.0885],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f1fe554",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_logits, top_k_indices = logits.topk(top_k, dim=-1) # [B, C, K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2fa668ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.4743, 0.4248], device='cuda:0', grad_fn=<TopkBackward0>),\n",
       "indices=tensor([0, 3], device='cuda:0'))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][0].topk(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "540b7025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 2]), torch.Size([3, 5, 2]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_logits.shape, top_k_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd622a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4743, 0.4248],\n",
       "          [0.7868, 0.2474],\n",
       "          [0.3426, 0.0723],\n",
       "          [0.4015, 0.3095],\n",
       "          [0.3849, 0.1197]],\n",
       " \n",
       "         [[1.8689, 1.5799],\n",
       "          [1.0262, 0.8318],\n",
       "          [0.8174, 0.8090],\n",
       "          [1.0447, 0.9106],\n",
       "          [1.3737, 1.2511]],\n",
       " \n",
       "         [[0.6926, 0.6080],\n",
       "          [0.1073, 0.0713],\n",
       "          [1.4745, 0.9555],\n",
       "          [3.5575, 1.2888],\n",
       "          [1.1467, 0.7076]]], device='cuda:0', grad_fn=<TopkBackward0>),\n",
       " tensor([[[0, 3],\n",
       "          [0, 7],\n",
       "          [3, 2],\n",
       "          [4, 0],\n",
       "          [1, 2]],\n",
       " \n",
       "         [[0, 7],\n",
       "          [4, 6],\n",
       "          [5, 2],\n",
       "          [0, 1],\n",
       "          [0, 5]],\n",
       " \n",
       "         [[3, 2],\n",
       "          [4, 7],\n",
       "          [2, 1],\n",
       "          [3, 6],\n",
       "          [3, 2]]], device='cuda:0'))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_logits, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92ed8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_probs = torch.full_like(logits, float('-inf'))  # [B, C, n_exp]\n",
    "router_probs.scatter_(dim=-1, index=top_k_indices, src=top_k_logits) # [B, C, n_exp]\n",
    "router_probs = F.softmax(router_probs, dim=-1) # [B, C, n_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80db3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124, 0.0000, 0.0000, 0.4876, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3683],\n",
       "         [0.0000, 0.0000, 0.4328, 0.5672, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4770, 0.0000, 0.0000, 0.0000, 0.5230, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5659, 0.4341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4283],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5485, 0.0000, 0.4515, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4979, 0.0000, 0.0000, 0.5021, 0.0000, 0.0000],\n",
       "         [0.5335, 0.4665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5306, 0.0000, 0.0000, 0.0000, 0.0000, 0.4694, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.4789, 0.5211, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5090, 0.0000, 0.0000, 0.4910],\n",
       "         [0.0000, 0.3731, 0.6269, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0000, 0.0937, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3919, 0.6081, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9972cf",
   "metadata": {},
   "source": [
    "### `router_probs[b][t]` is an `N_exp` dimensional vector that sums to 1\n",
    "- basically each token in the batch chooses 2 experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ff9fa84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5124, 0.0000, 0.0000, 0.4876, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_probs[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c7f4e2",
   "metadata": {},
   "source": [
    "### now we need to prepare batches for each experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e2a83bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert capacity: 4\n"
     ]
    }
   ],
   "source": [
    "# compute the expert capacity\n",
    "exp_capacity = math.floor(top_k * capacity_factor * num_tokens / n_exp)   \n",
    "exp_capacity += exp_capacity % 2 # make sure expert capacity is an even integer\n",
    "exp_capacity = int(exp_capacity)\n",
    "print(f\"expert capacity: {exp_capacity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d562df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6, 4],\n",
       "        [1, 1, 1],\n",
       "        [4, 7, 7]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(0, 8, (3,3 ))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e75a475c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(a, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a3e3008e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 3],\n",
       "         [0, 7],\n",
       "         [3, 2],\n",
       "         [4, 0],\n",
       "         [1, 2]],\n",
       "\n",
       "        [[0, 7],\n",
       "         [4, 6],\n",
       "         [5, 2],\n",
       "         [0, 1],\n",
       "         [0, 5]],\n",
       "\n",
       "        [[3, 2],\n",
       "         [4, 7],\n",
       "         [2, 1],\n",
       "         [3, 6],\n",
       "         [3, 2]]], device='cuda:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538cf5a",
   "metadata": {},
   "source": [
    "### Note: `F.one_hot` adds an extra dimension of length `num_classes` to the end of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f5b5958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 2, 8])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a multi-hot mask of chosen experts\n",
    "# values are 0 if expert not chosen, 1 if expert chosen\n",
    "exp_mask = F.one_hot(top_k_indices, num_classes=n_exp)  # [B, C, K, n_exp]\n",
    "exp_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cfade482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 2, 8])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask = exp_mask.view(num_tokens, top_k, n_exp)\n",
    "exp_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "05b67130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0] # mask for the first token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b3d77205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 8])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask = exp_mask.permute(1, 0, 2) # [K, B * C, n_exp]\n",
    "exp_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f84e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2db70dde",
   "metadata": {},
   "source": [
    "### `exp_mask[k][t]`: of shape `[K, num_tokens, N]` gives the k-th expert index for token t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7d7ad786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0] # first expert index for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "950d7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82ae4b",
   "metadata": {},
   "source": [
    "### `exp_mask[k][t]` --- the k-th expert selected by token `t` = a one-hot vector of size `N_exp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3329655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 4, 1, 0, 4, 5, 0, 0, 3, 4, 2, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(exp_mask[0], dim=-1) # first choice experts for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b6b58257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 7, 2, 0, 2, 7, 6, 2, 1, 5, 2, 7, 1, 6, 2], device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(exp_mask[1], dim=-1) # second chosen expert for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2feaa9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 8]),\n",
       " tensor([0, 0, 3, 4, 1, 0, 4, 5, 0, 0, 3, 4, 2, 3, 3, 3, 7, 2, 0, 2, 7, 6, 2, 1,\n",
       "         5, 2, 7, 1, 6, 2], device='cuda:0'))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank = exp_mask.reshape(top_k * num_tokens, n_exp) # just flatten the mask\n",
    "exp_rank.shape, exp_rank.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61cf3d",
   "metadata": {},
   "source": [
    "### `exp_rank[t]` is a one-hot vec of size N: expert chosen by token `t`\n",
    "- for easy viewing, do `exp_rank.argmax(dim=-1)` to see a flattened list of expert indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bb75074c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a4b11e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 7, 3],\n",
       "        [5, 3, 2, 7],\n",
       "        [7, 7, 1, 7],\n",
       "        [0, 2, 6, 5]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(0, 8, (4, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "90c7d9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  2,  7,  3],\n",
       "        [ 7,  5,  9, 10],\n",
       "        [14, 12, 10, 17],\n",
       "        [14, 14, 16, 22]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cumsum(a, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ad8e6fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4, 11, 14],\n",
       "        [ 5,  8, 10, 17],\n",
       "        [ 7, 14, 15, 22],\n",
       "        [ 0,  2,  8, 13]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cumsum(a, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbabeec",
   "metadata": {},
   "source": [
    "### why do cumsum and -1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "190b2359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62f1e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rank = torch.cumsum(exp_rank, dim=0) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0bc4ee26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1,  0, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1,  0,  0, -1, -1, -1],\n",
       "        [ 1,  0, -1,  0,  0, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  0, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  1, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 3,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  1,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  1,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  1,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  2,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  3,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  4,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  4,  2,  0, -1,  0],\n",
       "        [ 4,  0,  1,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  1,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  2,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  2,  4,  2,  0, -1,  1],\n",
       "        [ 5,  0,  2,  4,  2,  0,  0,  1],\n",
       "        [ 5,  0,  3,  4,  2,  0,  0,  1],\n",
       "        [ 5,  1,  3,  4,  2,  0,  0,  1],\n",
       "        [ 5,  1,  3,  4,  2,  1,  0,  1],\n",
       "        [ 5,  1,  4,  4,  2,  1,  0,  1],\n",
       "        [ 5,  1,  4,  4,  2,  1,  0,  2],\n",
       "        [ 5,  2,  4,  4,  2,  1,  0,  2],\n",
       "        [ 5,  2,  4,  4,  2,  1,  1,  2],\n",
       "        [ 5,  2,  5,  4,  2,  1,  1,  2]], device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f99fc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_rank.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "63f90b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1,  0, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1,  0,  0, -1, -1, -1],\n",
       "        [ 1,  0, -1,  0,  0, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  0, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  1, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 3,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  1,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  1,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  1,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  2,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  3,  2,  0, -1, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank = exp_rank.reshape(top_k, num_tokens, n_exp)  # [K, B * C, n_exp]\n",
    "exp_rank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b3a1c545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1,  0, -1, -1, -1, -1],\n",
       "        [ 1, -1, -1,  0,  0, -1, -1, -1],\n",
       "        [ 1,  0, -1,  0,  0, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  0, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  1, -1, -1, -1],\n",
       "        [ 2,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 3,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  0,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  1,  1,  0, -1, -1],\n",
       "        [ 4,  0, -1,  1,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  1,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  2,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  3,  2,  0, -1, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e5a78b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c61d88a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  0,  4,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  4,  2,  0, -1,  0],\n",
       "        [ 4,  0,  1,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  1,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  2,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  2,  4,  2,  0, -1,  1],\n",
       "        [ 5,  0,  2,  4,  2,  0,  0,  1],\n",
       "        [ 5,  0,  3,  4,  2,  0,  0,  1],\n",
       "        [ 5,  1,  3,  4,  2,  0,  0,  1],\n",
       "        [ 5,  1,  3,  4,  2,  1,  0,  1],\n",
       "        [ 5,  1,  4,  4,  2,  1,  0,  1],\n",
       "        [ 5,  1,  4,  4,  2,  1,  0,  2],\n",
       "        [ 5,  2,  4,  4,  2,  1,  0,  2],\n",
       "        [ 5,  2,  4,  4,  2,  1,  1,  2],\n",
       "        [ 5,  2,  5,  4,  2,  1,  1,  2]], device='cuda:0')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4c8f6986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aede7ca",
   "metadata": {},
   "source": [
    "## so far:\n",
    "- `exp_mask`: shape `[K, num_tokens, N]`\n",
    "- `exp_rank`: shape `[K, num_tokens, N]` --- it is just the cumsum(0) - 1 of `exp_mask`\n",
    "\n",
    "if any index in exp_rank is > exp_capacity => that expert will need to take more tokens --- avoid that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b6a7367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mask *= torch.lt(exp_rank, exp_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d86fd6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c257d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[1].sum(1) # here the 0s are the tokens that are dropped by the overflowing experts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cb115ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 8])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d7207",
   "metadata": {},
   "source": [
    "### reminder:\n",
    "## so far:\n",
    "- `exp_mask`: shape `[K, num_tokens, N]`\n",
    "- `exp_rank`: shape `[K, num_tokens, N]` --- it is just the cumsum(0) of `exp_mask`\n",
    "\n",
    "if any index in exp_rank is > exp_capacity => that expert will need to take more tokens --- avoid that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7865576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2766ee2c",
   "metadata": {},
   "source": [
    "## now we need to prepare batches for each expert of shape `[N, T, d]`\n",
    "- so far, better name for `exp_rank` is `exp_mask_cumsum`!\n",
    "- but now we are modifying `exp_rank` again!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9013f97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f3969e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  0,  4,  2,  0, -1, -1],\n",
       "        [ 4,  0,  0,  4,  2,  0, -1,  0],\n",
       "        [ 4,  0,  1,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  1,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  2,  4,  2,  0, -1,  0],\n",
       "        [ 5,  0,  2,  4,  2,  0, -1,  1],\n",
       "        [ 5,  0,  2,  4,  2,  0,  0,  1],\n",
       "        [ 5,  0,  3,  4,  2,  0,  0,  1],\n",
       "        [ 5,  1,  3,  4,  2,  0,  0,  1],\n",
       "        [ 5,  1,  3,  4,  2,  1,  0,  1],\n",
       "        [ 5,  1,  4,  4,  2,  1,  0,  1],\n",
       "        [ 5,  1,  4,  4,  2,  1,  0,  2],\n",
       "        [ 5,  2,  4,  4,  2,  1,  0,  2],\n",
       "        [ 5,  2,  4,  4,  2,  1,  1,  2],\n",
       "        [ 5,  2,  5,  4,  2,  1,  1,  2]], device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe8a6c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 2, 1, 0, 3, 0, 1, 2, 0, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(exp_mask[0] * exp_rank[0]).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c858a1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 2, 1, 0, 3, 1, 1, 0, 2, 2, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(exp_mask[1] * exp_rank[1]).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd40a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rank = torch.sum(exp_mask * exp_rank, dim=-1)  # [K, B * C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc6661",
   "metadata": {},
   "source": [
    "## now `exp_rank` is of shape `[K, num_tokens]`\n",
    "- the values are in range 0, 1, 2, ..., exp_capacity-1, i.e., upto the expert capacity!\n",
    "- `exp_rank[k][t]` = `k`-th expert choice by token `t`???\n",
    "\n",
    "\n",
    "## finally, I think we need to look at `exp_mask` and `exp_rank` tensors together!!\n",
    "- `exp_mask`: says which expert to choose for token `t`, say it is expert `e`\n",
    "- `exp_rank`: says where the token `t` is fitted onto the batch for expert `e`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "79de523c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 2, 1, 0, 3, 0, 1, 2, 0, 2, 3],\n",
       "        [0, 0, 1, 0, 2, 1, 0, 3, 1, 1, 0, 2, 2, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c0da26b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 2, 1, 0, 3, 0, 1, 2, 0, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7633e1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124, 0.0000, 0.0000, 0.4876, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3683],\n",
       "         [0.0000, 0.0000, 0.4328, 0.5672, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4770, 0.0000, 0.0000, 0.0000, 0.5230, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5659, 0.4341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4283],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5485, 0.0000, 0.4515, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4979, 0.0000, 0.0000, 0.5021, 0.0000, 0.0000],\n",
       "         [0.5335, 0.4665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5306, 0.0000, 0.0000, 0.0000, 0.0000, 0.4694, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.4789, 0.5211, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5090, 0.0000, 0.0000, 0.4910],\n",
       "         [0.0000, 0.3731, 0.6269, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0000, 0.0937, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3919, 0.6081, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3ed81cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124, 0.0000, 0.0000, 0.4876, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3683],\n",
       "         [0.0000, 0.0000, 0.4328, 0.5672, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4770, 0.0000, 0.0000, 0.0000, 0.5230, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5659, 0.4341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4283],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5485, 0.0000, 0.4515, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4979, 0.0000, 0.0000, 0.5021, 0.0000, 0.0000],\n",
       "         [0.5335, 0.4665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5306, 0.0000, 0.0000, 0.0000, 0.0000, 0.4694, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4789, 0.5211, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5090, 0.0000, 0.0000, 0.4910],\n",
       "         [0.0000, 0.3731, 0.6269, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0000, 0.0937, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3919, 0.6081, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask probabilities to only include selected experts\n",
    "router_probs = router_probs.view(num_tokens, n_exp)[None, :] # [1, B * C, n_exp]\n",
    "router_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "741d452b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 8])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "17e841ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_weights = exp_mask * router_probs # [K, B * C, n_exp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57717f0e",
   "metadata": {},
   "source": [
    "### `exp_weights` will be used later to aggregate expert outputs for each token!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3dafb665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.5672, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5230, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5659, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5485, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5021, 0.0000, 0.0000],\n",
       "         [0.5335, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.5211, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5090, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.6269, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.6081, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3683],\n",
       "         [0.0000, 0.0000, 0.4328, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4283],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4515, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.4665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4694, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4910],\n",
       "         [0.0000, 0.3731, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0937, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53f80798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_mask[0], exp_rank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7b67abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_mask[1], exp_rank[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "01106389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 2, 1, 0, 3, 0, 1, 2, 0, 2, 3],\n",
       "        [0, 0, 1, 0, 2, 1, 0, 3, 1, 1, 0, 2, 2, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "27d8c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position of each token within the capacity of the selected expert\n",
    "exp_rank_sc = F.one_hot(exp_rank, num_classes=exp_capacity) # [K, B * C, exp_capacity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2ca78f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 1, 4])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank_sc.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "63f1979f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 8, 1])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weights.unsqueeze(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d17801a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.6317, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3683, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.4328, 0.0000, 0.0000],\n",
       "         [0.5672, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5230, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5659, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4341, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.5717, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.4283, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5485, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4515, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.4979],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5021, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.5335],\n",
       "         [0.0000, 0.4665, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.4694, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5211, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5090, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4910, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3731, 0.0000],\n",
       "         [0.6269, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9063, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0937, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.6081],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]]], device='cuda:0',\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight of selected expert for each token at position the capacity of that expert \n",
    "exp_weights = torch.sum(exp_weights.unsqueeze(3) * exp_rank_sc.unsqueeze(2), dim=0) # [B * C, n_exp, exp_capacity]\n",
    "exp_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06511600",
   "metadata": {},
   "source": [
    "## now we have changed `exp_mask` again!!!\n",
    "- the clever thing here is: now we don't need two arrays!!! both which expert a token goes to, and where it fits on its batch are available in this new `exp_mask`!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "83a9be36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False,  True, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [ True, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [ True, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [ True, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [ True, False, False, False],\n",
       "         [False, False,  True, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False,  True, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False,  True, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False, False, False, False],\n",
       "         [ True, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [ True, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False,  True],\n",
       "         [False,  True, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False,  True, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False,  True, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False,  True, False],\n",
       "         [ True, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False,  True, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False, False, False, False]],\n",
       "\n",
       "        [[False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False,  True],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False],\n",
       "         [False, False, False, False]]], device='cuda:0')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask = exp_weights.bool() # binary mask of selected experts for each token\n",
    "exp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6d44cc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c5766904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b81832fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0], device='cuda:0'),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0].float().argmax(dim=0), exp_mask[0].float().argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fce5852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False,  True, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1e189e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1365,  0.0541,  0.2719, -0.9899, -0.7248, -0.6059],\n",
       "          [ 0.1628, -0.1554,  1.5273, -0.3510,  1.2115, -0.2123],\n",
       "          [-0.9377, -0.7252, -0.3097,  0.3768,  1.1407,  1.1331],\n",
       "          [ 0.2010, -0.1841,  2.2202,  1.4859,  0.7512,  0.5559],\n",
       "          [ 1.7039, -0.9790,  0.1105, -0.7734, -0.6472, -0.4575]],\n",
       " \n",
       "         [[-0.8361, -0.1136, -1.6439, -0.1146,  2.9494,  0.2525],\n",
       "          [ 0.7155, -0.1714, -2.2199,  0.8281, -0.4643,  0.4119],\n",
       "          [-0.0201, -1.1501, -0.2059,  0.2940,  0.5312,  0.7576],\n",
       "          [ 1.0061, -0.2905,  1.0959,  2.9464, -0.1513, -1.1484],\n",
       "          [-1.4739,  0.0631,  0.2748, -0.4627,  0.1258, -2.8403]],\n",
       " \n",
       "         [[ 0.7438, -1.0722, -1.1704,  1.1269,  0.1164,  0.7960],\n",
       "          [-0.9100,  0.2720, -0.6133, -0.6931, -1.9131,  0.1259],\n",
       "          [ 1.5127,  0.6726,  0.7120, -0.2075, -1.2958, -0.2812],\n",
       "          [-3.8353,  0.6175,  1.8978, -1.7567, -1.0222, -0.5394],\n",
       "          [-0.6475, -0.1961, -0.0973, -0.9135,  1.5937,  1.2666]]],\n",
       "        device='cuda:0'),\n",
       " torch.Size([3, 5, 6]))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cfae3cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1365,  0.0541,  0.2719, -0.9899, -0.7248, -0.6059],\n",
       "        [ 0.1628, -0.1554,  1.5273, -0.3510,  1.2115, -0.2123],\n",
       "        [-0.9377, -0.7252, -0.3097,  0.3768,  1.1407,  1.1331],\n",
       "        [ 0.2010, -0.1841,  2.2202,  1.4859,  0.7512,  0.5559],\n",
       "        [ 1.7039, -0.9790,  0.1105, -0.7734, -0.6472, -0.4575],\n",
       "        [-0.8361, -0.1136, -1.6439, -0.1146,  2.9494,  0.2525],\n",
       "        [ 0.7155, -0.1714, -2.2199,  0.8281, -0.4643,  0.4119],\n",
       "        [-0.0201, -1.1501, -0.2059,  0.2940,  0.5312,  0.7576],\n",
       "        [ 1.0061, -0.2905,  1.0959,  2.9464, -0.1513, -1.1484],\n",
       "        [-1.4739,  0.0631,  0.2748, -0.4627,  0.1258, -2.8403],\n",
       "        [ 0.7438, -1.0722, -1.1704,  1.1269,  0.1164,  0.7960],\n",
       "        [-0.9100,  0.2720, -0.6133, -0.6931, -1.9131,  0.1259],\n",
       "        [ 1.5127,  0.6726,  0.7120, -0.2075, -1.2958, -0.2812],\n",
       "        [-3.8353,  0.6175,  1.8978, -1.7567, -1.0222, -0.5394],\n",
       "        [-0.6475, -0.1961, -0.0973, -0.9135,  1.5937,  1.2666]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape tokens into batches for each expert, return both weights and batches\n",
    "# [n_exp, exp_capacity, B * C] * [B * C, d] -> [n_exp, exp_capacity, n_embd]\n",
    "x = x.view(num_tokens, d)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "739b7809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 8, 4]), torch.Size([15, 6]), torch.Size([8, 4, 15]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask.shape, x.shape, exp_mask.permute(1, 2, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2d9ef431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_mask.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6127f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_batches = exp_mask.permute(1, 2, 0).type_as(x) @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3935a56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 6])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "990f57c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1365,  0.0541,  0.2719, -0.9899, -0.7248, -0.6059],\n",
       "        [ 0.1628, -0.1554,  1.5273, -0.3510,  1.2115, -0.2123],\n",
       "        [-0.9377, -0.7252, -0.3097,  0.3768,  1.1407,  1.1331],\n",
       "        [ 0.2010, -0.1841,  2.2202,  1.4859,  0.7512,  0.5559],\n",
       "        [ 1.7039, -0.9790,  0.1105, -0.7734, -0.6472, -0.4575],\n",
       "        [-0.8361, -0.1136, -1.6439, -0.1146,  2.9494,  0.2525],\n",
       "        [ 0.7155, -0.1714, -2.2199,  0.8281, -0.4643,  0.4119],\n",
       "        [-0.0201, -1.1501, -0.2059,  0.2940,  0.5312,  0.7576],\n",
       "        [ 1.0061, -0.2905,  1.0959,  2.9464, -0.1513, -1.1484],\n",
       "        [-1.4739,  0.0631,  0.2748, -0.4627,  0.1258, -2.8403],\n",
       "        [ 0.7438, -1.0722, -1.1704,  1.1269,  0.1164,  0.7960],\n",
       "        [-0.9100,  0.2720, -0.6133, -0.6931, -1.9131,  0.1259],\n",
       "        [ 1.5127,  0.6726,  0.7120, -0.2075, -1.2958, -0.2812],\n",
       "        [-3.8353,  0.6175,  1.8978, -1.7567, -1.0222, -0.5394],\n",
       "        [-0.6475, -0.1961, -0.0973, -0.9135,  1.5937,  1.2666]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "74bb4997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0201, -1.1501, -0.2059,  0.2940,  0.5312,  0.7576],\n",
       "        [-1.4739,  0.0631,  0.2748, -0.4627,  0.1258, -2.8403],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_batches[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceacb73",
   "metadata": {},
   "source": [
    "### combining expert outputs now!\n",
    "- now we have batches for each expert of shape `[N, C, d]` that we can directly feed into the expert layers!!!\n",
    "\n",
    "\n",
    "## `exp_weights` of shape `[num_tokens, N, C]`\n",
    "\n",
    "## `exp_mask` of shape `[num_tokens, N, C]`\n",
    "\n",
    "## `exp_batches` of shape `[N, C, d]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "beb0b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPExperts(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d,\n",
    "        n_exp=8,\n",
    "        bias=False,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        d: size of embedding dimension\n",
    "        n_exp: the number of experts to create in the expert layer\n",
    "        bias: whether or not to use bias in linear layers\n",
    "        dropout: probability of dropout\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.c_fc = nn.Parameter(torch.empty(n_exp, d, 4 * d))\n",
    "        self.c_proj = nn.Parameter(torch.empty(n_exp, 4 * d, d))\n",
    "        self.fc_bias = nn.Parameter(torch.empty(n_exp, 1, 4 * d)) if self.bias else None\n",
    "        self.proj_bias = nn.Parameter(torch.empty(n_exp, 1, d)) if self.bias else None\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # initialize the parameters\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.c_fc)\n",
    "        nn.init.xavier_uniform_(self.c_proj)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # here x is [N, T, d] shaped where N is the number of experts to make torch.bmm work [N, T, d] x [N, d, 4d]\n",
    "        x = torch.bmm(x, self.c_fc) # replace torch.bmm with torch.matmul\n",
    "        if self.bias:\n",
    "            x += self.fc_bias\n",
    "        x = self.gelu(x)\n",
    "        x = torch.bmm(x, self.c_proj) # replace torch.bmm with torch.matmul\n",
    "        if self.bias:\n",
    "            x += self.proj_bias\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "637e9fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 8, 4]), torch.Size([15, 8, 4]), torch.Size([8, 4, 6]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weights.shape, exp_mask.shape, expert_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "803f4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a529ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = MLPExperts(d=6, n_exp=n_exp, bias=True, dropout=0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d00ac806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1365,  0.0541,  0.2719, -0.9899, -0.7248, -0.6059],\n",
       "         [ 0.1628, -0.1554,  1.5273, -0.3510,  1.2115, -0.2123],\n",
       "         [-0.9377, -0.7252, -0.3097,  0.3768,  1.1407,  1.1331],\n",
       "         [ 0.2010, -0.1841,  2.2202,  1.4859,  0.7512,  0.5559],\n",
       "         [ 1.7039, -0.9790,  0.1105, -0.7734, -0.6472, -0.4575]],\n",
       "\n",
       "        [[-0.8361, -0.1136, -1.6439, -0.1146,  2.9494,  0.2525],\n",
       "         [ 0.7155, -0.1714, -2.2199,  0.8281, -0.4643,  0.4119],\n",
       "         [-0.0201, -1.1501, -0.2059,  0.2940,  0.5312,  0.7576],\n",
       "         [ 1.0061, -0.2905,  1.0959,  2.9464, -0.1513, -1.1484],\n",
       "         [-1.4739,  0.0631,  0.2748, -0.4627,  0.1258, -2.8403]],\n",
       "\n",
       "        [[ 0.7438, -1.0722, -1.1704,  1.1269,  0.1164,  0.7960],\n",
       "         [-0.9100,  0.2720, -0.6133, -0.6931, -1.9131,  0.1259],\n",
       "         [ 1.5127,  0.6726,  0.7120, -0.2075, -1.2958, -0.2812],\n",
       "         [-3.8353,  0.6175,  1.8978, -1.7567, -1.0222, -0.5394],\n",
       "         [-0.6475, -0.1961, -0.0973, -0.9135,  1.5937,  1.2666]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(3, 5, d)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "64ca8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_outs = experts(expert_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "78cf64e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 6])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_outs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c6f59",
   "metadata": {},
   "source": [
    "## aggregate expert outputs \n",
    "-- this is actually the task of `MoELayer` class: the heavy-lifting of preparing the batches and weights is already done by the `Router` class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "672a3918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5124, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fa6d8bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "88f7685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6317, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3683, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "52db309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "611d1f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5124, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.6317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3683, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.4328, 0.0000, 0.0000, 0.5672, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5230, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5659, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.4341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.5717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.4283, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5485,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4515, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.4979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.5021, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5335, 0.0000, 0.4665, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.4694, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.5211, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.5090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.4910, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3731, 0.0000, 0.6269,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0937, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6081, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weight = exp_weights.view(num_tokens, -1) # [BT, N, C]\n",
    "exp_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3ec69d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 32])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "928dc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_out = exp_outs.view(-1, d) # [NC, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "30f1d65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 6])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "47578ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "765066e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = exp_weight @ exp_out # [B * T, n_embd]\n",
    "output = output.view(B, T, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "726e19b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7941e-03,  7.8108e-04, -1.3030e-04, -7.1611e-04, -8.9831e-04,\n",
       "          -1.1864e-02],\n",
       "         [-5.3006e-02,  2.2440e-02,  5.0095e-02,  2.7050e-02, -6.7775e+31,\n",
       "          -3.5880e-02],\n",
       "         [ 2.3727e-02,  1.6750e-02, -3.6671e-02,  5.0149e-02,  2.6458e-02,\n",
       "           7.6879e-02],\n",
       "         [-7.8519e-02,  4.5484e-02,  1.2097e-02, -2.1896e-02, -4.4047e-03,\n",
       "          -4.5420e-02],\n",
       "         [ 1.8227e+04,  9.2313e+03,  1.8427e+18, -5.3106e+03,  3.0605e+03,\n",
       "          -8.6336e+03]],\n",
       "\n",
       "        [[ 6.0383e-02,  2.2804e-02,  8.0370e-03,  4.3165e-02, -7.8779e+31,\n",
       "           8.6624e-02],\n",
       "         [ 2.5009e-02, -3.9123e-02, -2.6364e-02,  1.3211e-02,  6.4989e+17,\n",
       "           9.5384e-03],\n",
       "         [-2.8894e-03,  2.9288e-02,  2.6225e-02, -1.5221e-02, -9.2343e+31,\n",
       "           1.3288e-02],\n",
       "         [ 1.5027e+04,  2.2557e-02,  1.5191e+18, -4.3782e+03,  2.5250e+03,\n",
       "           8.2127e-03],\n",
       "         [ 4.1349e-02, -3.9658e-02, -3.7538e-03,  4.3785e-02,  0.0000e+00,\n",
       "           2.7552e-02]],\n",
       "\n",
       "        [[-1.2608e-02,  0.0000e+00,  0.0000e+00, -2.1484e-03, -2.5996e-02,\n",
       "           2.3484e-02],\n",
       "         [ 3.2044e-03, -4.0892e-02,  2.5247e-02, -1.2556e-02,  4.5882e-03,\n",
       "           3.6411e-02],\n",
       "         [ 1.2015e+04,  6.0851e+03,  1.2147e+18, -5.6672e-02, -2.5753e-02,\n",
       "           0.0000e+00],\n",
       "         [ 1.3308e-01, -1.6209e-02, -5.1641e-03,  3.9515e-02,  1.3490e+17,\n",
       "           9.9688e-03],\n",
       "         [ 0.0000e+00, -4.6380e-02,  2.5249e-02,  0.0000e+00,  2.5249e-02,\n",
       "           8.8530e-02]]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4a6f6",
   "metadata": {},
   "source": [
    "## load balancing, auxiliary losses!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0d8f1079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5124, 0.0000, 0.0000, 0.4876, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3683],\n",
       "         [0.0000, 0.0000, 0.4328, 0.5672, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4770, 0.0000, 0.0000, 0.0000, 0.5230, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5659, 0.4341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4283],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5485, 0.0000, 0.4515, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4979, 0.0000, 0.0000, 0.5021, 0.0000, 0.0000],\n",
       "         [0.5335, 0.4665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5306, 0.0000, 0.0000, 0.0000, 0.0000, 0.4694, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.4789, 0.5211, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5090, 0.0000, 0.0000, 0.4910],\n",
       "         [0.0000, 0.3731, 0.6269, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9063, 0.0000, 0.0000, 0.0937, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3919, 0.6081, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_probs = router_probs.view(3, 5, n_exp)\n",
    "router_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "477b0166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 3],\n",
       "         [0, 7],\n",
       "         [3, 2],\n",
       "         [4, 0],\n",
       "         [1, 2]],\n",
       "\n",
       "        [[0, 7],\n",
       "         [4, 6],\n",
       "         [5, 2],\n",
       "         [0, 1],\n",
       "         [0, 5]],\n",
       "\n",
       "        [[3, 2],\n",
       "         [4, 7],\n",
       "         [2, 1],\n",
       "         [3, 6],\n",
       "         [3, 2]]], device='cuda:0')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "431778a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 0, 0, 1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [0, 0, 1, 1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 1, 1, 0, 0, 0, 0, 0]],\n",
       " \n",
       "         [[1, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [0, 0, 0, 0, 1, 0, 1, 0],\n",
       "          [0, 0, 1, 0, 0, 1, 0, 0],\n",
       "          [1, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "         [[0, 0, 1, 1, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 1],\n",
       "          [0, 1, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 1, 0],\n",
       "          [0, 0, 1, 1, 0, 0, 0, 0]]], device='cuda:0'),\n",
       " torch.Size([3, 5, 8]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_indices = F.one_hot(top_k_indices, num_classes=n_exp)\n",
    "one_hot_indices = one_hot_indices.sum(dim=2)\n",
    "one_hot_indices, one_hot_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4979adaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.2000, 0.4000, 0.3333, 0.2000, 0.1333, 0.1333, 0.2000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_expert = torch.mean(one_hot_indices.float(), dim=(0, 1))\n",
    "tokens_per_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e5d6714b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., device='cuda:0')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_per_expert.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cef6893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2171, 0.0937, 0.1908, 0.2060, 0.1054, 0.0648, 0.0364, 0.0858],\n",
       "       device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_per_expert = torch.mean(router_probs, dim=(0, 1))\n",
    "prob_per_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "87d18d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_per_expert.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a422d",
   "metadata": {},
   "source": [
    "## `tokens_per_expert`: token loads per expert\n",
    "- fraction of tokens in a batch sent to each expert\n",
    "- need not sum to 1 over all N elements in the vector\n",
    "- ideally should be evenly distributed, i.e., each expert gets a fair share of the load\n",
    "- this term is not differentiable\n",
    "\n",
    "## `prob_per_expert`:\n",
    "- router assigned probabilities to each expert, averaged over the entire batch\n",
    "- this vector sums to 1\n",
    "- this is differentiable\n",
    "- ideally should be as uniform as possible, i.e., router should not be biased towards any single expert for a batch of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff59de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16be386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b37fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e719f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
